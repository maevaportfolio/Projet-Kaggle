{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: orange;\">Mod√©lisation - Pr√©diction du Taux de Grippe</span>\n",
    "\n",
    "---\n",
    "\n",
    "### <span style=\"color: green;\">Introduction</span>\n",
    "\n",
    "**Objectif** : Pr√©dire le taux de grippe pour 100 000 habitants par r√©gion fran√ßaise pour des semaines sp√©cifiques.\n",
    "\n",
    "**Structure des donn√©es** : Donn√©es de panel (r√©gions √ó semaines) n√©cessitant un traitement sp√©cifique pour le d√©coupage train/validation.\n",
    "\n",
    "**Approche** : Du plus simple au plus complexe\n",
    "1. Mod√®les na√Øfs (baseline)\n",
    "2. R√©gression lin√©aire adapt√©e aux panels\n",
    "3. Mod√®les ARIMA\n",
    "4. Mod√®les ML (Prophet, Random Forest, XGBoost)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">1. Import des Librairies</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies de base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Mod√®les ML\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# XGBoost & LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# S√©ries temporelles\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librairies import√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">2. Chargement et Pr√©paration des Donn√©es</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "df = pd.read_csv('train_final.csv')\n",
    "\n",
    "print(f\"üìä Dimensions initiales : {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "print(f\"üìÖ P√©riode : {df['week'].min()} - {df['week'].max()}\")\n",
    "print(f\"üó∫Ô∏è  R√©gions : {df['region_name'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des dates\n",
    "df['week_date'] = pd.to_datetime(df['week_date'])\n",
    "df['month_date'] = pd.to_datetime(df['month_date'])\n",
    "\n",
    "# Extraction de l'ann√©e et du num√©ro de semaine\n",
    "df['year'] = df['year'].astype(int)\n",
    "df['week_num'] = df['week'].astype(str).str[-2:].astype(int)\n",
    "\n",
    "# Tri par r√©gion et par date (CRUCIAL pour les donn√©es de panel)\n",
    "df = df.sort_values(['region_name', 'week_date']).reset_index(drop=True)\n",
    "\n",
    "print(\"‚úÖ Donn√©es tri√©es par r√©gion et par date\")\n",
    "df[['region_name', 'week', 'week_date', 'year', 'week_num', 'TauxGrippe']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">3. Feature Engineering</span>\n",
    "\n",
    "### 3.1 Cr√©ation des variables temporelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables temporelles additionnelles\n",
    "df['month_num'] = df['week_date'].dt.month\n",
    "df['quarter'] = df['week_date'].dt.quarter\n",
    "df['day_of_year'] = df['week_date'].dt.dayofyear\n",
    "\n",
    "# Indicateur de saison grippale (octobre √† mars)\n",
    "df['saison_grippe'] = df['month_num'].apply(lambda x: 1 if x in [10, 11, 12, 1, 2, 3] else 0)\n",
    "\n",
    "# Variables cycliques pour capturer la saisonnalit√©\n",
    "df['sin_week'] = np.sin(2 * np.pi * df['week_num'] / 52)\n",
    "df['cos_week'] = np.cos(2 * np.pi * df['week_num'] / 52)\n",
    "df['sin_month'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['cos_month'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "print(\"‚úÖ Variables temporelles cr√©√©es\")\n",
    "df[['week_date', 'month_num', 'quarter', 'saison_grippe', 'sin_week', 'cos_week']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cr√©ation des Lags (Variables Retard√©es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des lags PAR R√âGION (tr√®s important pour les donn√©es de panel)\n",
    "def create_lags(data, column, lags, group_col='region_name'):\n",
    "    \"\"\"\n",
    "    Cr√©e des variables retard√©es (lags) pour une colonne donn√©e, group√©es par r√©gion.\n",
    "    \"\"\"\n",
    "    df_temp = data.copy()\n",
    "    for lag in lags:\n",
    "        df_temp[f'{column}_lag{lag}'] = df_temp.groupby(group_col)[column].shift(lag)\n",
    "    return df_temp\n",
    "\n",
    "# Lags pour TauxGrippe (t-1, t-2, t-3, t-4 semaines)\n",
    "lags_to_create = [1, 2, 3, 4]\n",
    "df = create_lags(df, 'TauxGrippe', lags_to_create)\n",
    "\n",
    "# Lags pour les requ√™tes Google\n",
    "df = create_lags(df, 'requete_grippe', [1, 2])\n",
    "\n",
    "print(\"‚úÖ Variables de lag cr√©√©es\")\n",
    "lag_cols = [col for col in df.columns if 'lag' in col]\n",
    "print(f\"   Colonnes de lag : {lag_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyennes mobiles par r√©gion\n",
    "def create_rolling_features(data, column, windows, group_col='region_name'):\n",
    "    \"\"\"\n",
    "    Cr√©e des moyennes mobiles pour une colonne donn√©e, group√©es par r√©gion.\n",
    "    \"\"\"\n",
    "    df_temp = data.copy()\n",
    "    for window in windows:\n",
    "        df_temp[f'{column}_rolling_mean_{window}'] = df_temp.groupby(group_col)[column].transform(\n",
    "            lambda x: x.shift(1).rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df_temp[f'{column}_rolling_std_{window}'] = df_temp.groupby(group_col)[column].transform(\n",
    "            lambda x: x.shift(1).rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "    return df_temp\n",
    "\n",
    "# Moyennes mobiles sur 4 et 8 semaines\n",
    "df = create_rolling_features(df, 'TauxGrippe', [4, 8])\n",
    "\n",
    "print(\"‚úÖ Moyennes mobiles cr√©√©es\")\n",
    "rolling_cols = [col for col in df.columns if 'rolling' in col]\n",
    "print(f\"   Colonnes rolling : {rolling_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Encodage des R√©gions (Dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des dummies pour les r√©gions\n",
    "region_dummies = pd.get_dummies(df['region_name'], prefix='region', drop_first=True)\n",
    "df = pd.concat([df, region_dummies], axis=1)\n",
    "\n",
    "print(f\"‚úÖ Dummies r√©gions cr√©√©es : {region_dummies.shape[1]} colonnes\")\n",
    "print(f\"   R√©gions encod√©es : {list(region_dummies.columns)[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding pour les mod√®les qui ne supportent pas les dummies\n",
    "le_region = LabelEncoder()\n",
    "df['region_encoded'] = le_region.fit_transform(df['region_name'])\n",
    "\n",
    "# Mapping pour r√©f√©rence\n",
    "region_mapping = dict(zip(le_region.classes_, le_region.transform(le_region.classes_)))\n",
    "print(\"‚úÖ Label Encoding des r√©gions\")\n",
    "print(f\"   Exemple : ALSACE ‚Üí {region_mapping.get('ALSACE', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Ratios d√©mographiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de ratios pour √©viter la multicollin√©arit√©\n",
    "df['ratio_jeunes'] = df['pop_0_19'] / df['pop_total']\n",
    "df['ratio_seniors'] = df['pop_75_plus'] / df['pop_total']\n",
    "df['ratio_actifs'] = (df['pop_20_39'] + df['pop_40_59']) / df['pop_total']\n",
    "\n",
    "print(\"‚úÖ Ratios d√©mographiques cr√©√©s\")\n",
    "df[['region_name', 'pop_total', 'ratio_jeunes', 'ratio_seniors', 'ratio_actifs']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des valeurs manquantes apr√®s feature engineering\n",
    "missing_after_fe = df.isnull().sum()\n",
    "missing_cols = missing_after_fe[missing_after_fe > 0]\n",
    "\n",
    "print(\"üìä Valeurs manquantes apr√®s Feature Engineering :\")\n",
    "if len(missing_cols) > 0:\n",
    "    for col, val in missing_cols.items():\n",
    "        print(f\"   {col}: {val} ({val/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"   Aucune valeur manquante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu du dataset final\n",
    "print(f\"\\nüìä Dimensions apr√®s Feature Engineering : {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "print(f\"\\nüìã Liste des colonnes :\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">4. D√©coupage Train / Validation (Temporel)</span>\n",
    "\n",
    "**Important** : Pour les donn√©es de panel temporelles, on ne fait PAS de split al√©atoire. On garde l'ordre chronologique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©coupage temporel : 80% train, 20% validation\n",
    "# On prend les derni√®res semaines pour la validation\n",
    "\n",
    "# Identifier les semaines uniques tri√©es\n",
    "unique_weeks = df['week'].sort_values().unique()\n",
    "n_weeks = len(unique_weeks)\n",
    "\n",
    "# Point de coupure (80% des semaines pour l'entra√Ænement)\n",
    "split_idx = int(n_weeks * 0.8)\n",
    "train_weeks = unique_weeks[:split_idx]\n",
    "val_weeks = unique_weeks[split_idx:]\n",
    "\n",
    "print(f\"üìä D√âCOUPAGE TEMPOREL\")\n",
    "print(f\"   Semaines totales : {n_weeks}\")\n",
    "print(f\"   Semaines train   : {len(train_weeks)} ({train_weeks[0]} ‚Üí {train_weeks[-1]})\")\n",
    "print(f\"   Semaines valid.  : {len(val_weeks)} ({val_weeks[0]} ‚Üí {val_weeks[-1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des ensembles train et validation\n",
    "df_train = df[df['week'].isin(train_weeks)].copy()\n",
    "df_val = df[df['week'].isin(val_weeks)].copy()\n",
    "\n",
    "print(f\"\\nüìä TAILLES DES ENSEMBLES\")\n",
    "print(f\"   Train      : {len(df_train)} observations ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Validation : {len(df_val)} observations ({len(df_val)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes avec NaN (dues aux lags) pour la mod√©lisation\n",
    "# On garde une copie avec NaN pour certains mod√®les\n",
    "df_train_clean = df_train.dropna().copy()\n",
    "df_val_clean = df_val.dropna().copy()\n",
    "\n",
    "print(f\"\\nüìä APR√àS SUPPRESSION DES NaN (dus aux lags)\")\n",
    "print(f\"   Train      : {len(df_train_clean)} observations\")\n",
    "print(f\"   Validation : {len(df_val_clean)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">5. D√©finition des Features et Target</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable cible\n",
    "target = 'TauxGrippe'\n",
    "\n",
    "# Features de base (sans dummies r√©gions)\n",
    "base_features = [\n",
    "    # Lags\n",
    "    'TauxGrippe_lag1', 'TauxGrippe_lag2', 'TauxGrippe_lag3', 'TauxGrippe_lag4',\n",
    "    'requete_grippe_lag1', 'requete_grippe_lag2',\n",
    "    # Rolling\n",
    "    'TauxGrippe_rolling_mean_4', 'TauxGrippe_rolling_mean_8',\n",
    "    'TauxGrippe_rolling_std_4', 'TauxGrippe_rolling_std_8',\n",
    "    # Requ√™tes Google\n",
    "    'requete_grippe', 'requete_grippe_aviaire_vaccin',\n",
    "    # Temporel\n",
    "    'week_num', 'month_num', 'quarter', 'saison_grippe',\n",
    "    'sin_week', 'cos_week', 'sin_month', 'cos_month',\n",
    "    # D√©mographie (ratios)\n",
    "    'ratio_jeunes', 'ratio_seniors', 'ratio_actifs',\n",
    "    'pop_total'\n",
    "]\n",
    "\n",
    "# Features avec dummies r√©gions\n",
    "region_dummy_cols = [col for col in df.columns if col.startswith('region_')]\n",
    "features_with_dummies = base_features + region_dummy_cols\n",
    "\n",
    "# Features avec label encoding r√©gion\n",
    "features_with_label = base_features + ['region_encoded']\n",
    "\n",
    "print(f\"üìä FEATURES D√âFINIES\")\n",
    "print(f\"   Base features          : {len(base_features)}\")\n",
    "print(f\"   Avec dummies r√©gions   : {len(features_with_dummies)}\")\n",
    "print(f\"   Avec label encoding    : {len(features_with_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es pour les mod√®les ML\n",
    "# V√©rifier que toutes les features existent\n",
    "available_features = [f for f in features_with_dummies if f in df_train_clean.columns]\n",
    "missing_features = [f for f in features_with_dummies if f not in df_train_clean.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"‚ö†Ô∏è Features manquantes : {missing_features}\")\n",
    "    features_with_dummies = available_features\n",
    "\n",
    "X_train = df_train_clean[features_with_dummies]\n",
    "y_train = df_train_clean[target]\n",
    "X_val = df_val_clean[features_with_dummies]\n",
    "y_val = df_val_clean[target]\n",
    "\n",
    "print(f\"\\nüìä DIMENSIONS FINALES\")\n",
    "print(f\"   X_train : {X_train.shape}\")\n",
    "print(f\"   y_train : {y_train.shape}\")\n",
    "print(f\"   X_val   : {X_val.shape}\")\n",
    "print(f\"   y_val   : {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">6. Fonctions d'√âvaluation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Calcule et affiche les m√©triques d'√©valuation.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100  # +epsilon pour √©viter div/0\n",
    "    \n",
    "    print(f\"\\nüìä {model_name}\")\n",
    "    print(f\"   RMSE : {rmse:.2f}\")\n",
    "    print(f\"   MAE  : {mae:.2f}\")\n",
    "    print(f\"   R¬≤   : {r2:.4f}\")\n",
    "    print(f\"   MAPE : {mape:.2f}%\")\n",
    "    \n",
    "    return {'model': model_name, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, model_name=\"Model\", n_points=200):\n",
    "    \"\"\"\n",
    "    Visualise les pr√©dictions vs valeurs r√©elles.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(y_true[:n_points], y_pred[:n_points], alpha=0.5, color='steelblue')\n",
    "    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    axes[0].set_xlabel('Valeurs R√©elles')\n",
    "    axes[0].set_ylabel('Pr√©dictions')\n",
    "    axes[0].set_title(f'{model_name} - Pr√©dictions vs R√©elles')\n",
    "    \n",
    "    # Distribution des erreurs\n",
    "    errors = y_pred - y_true\n",
    "    axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "    axes[1].axvline(0, color='red', linestyle='--', lw=2)\n",
    "    axes[1].set_xlabel('Erreur (Pr√©diction - R√©el)')\n",
    "    axes[1].set_ylabel('Fr√©quence')\n",
    "    axes[1].set_title(f'{model_name} - Distribution des Erreurs')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Stockage des r√©sultats\n",
    "results = []\n",
    "print(\"‚úÖ Fonctions d'√©valuation d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: blue;\">PARTIE 1 : MOD√àLES NA√èFS (BASELINE)</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">7. Mod√®les Na√Øfs</span>\n",
    "\n",
    "### 7.1 Mod√®le Na√Øf Simple (Persistance)\n",
    "\n",
    "$$\\hat{y}_{T+h|T} = y_T$$\n",
    "\n",
    "La pr√©diction est √©gale √† la derni√®re observation connue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le Na√Øf Simple : pr√©diction = valeur de la semaine pr√©c√©dente (lag1)\n",
    "y_pred_naive_simple = df_val_clean['TauxGrippe_lag1'].values\n",
    "\n",
    "# √âvaluation\n",
    "res_naive_simple = evaluate_model(y_val.values, y_pred_naive_simple, \"Na√Øf Simple (Persistance)\")\n",
    "results.append(res_naive_simple)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_naive_simple, \"Na√Øf Simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Mod√®le Na√Øf Saisonnier\n",
    "\n",
    "$$\\hat{y}_{T+h|T} = y_{T+h-km}$$\n",
    "\n",
    "o√π m = p√©riode saisonni√®re (52 semaines) et k = nombre d'ann√©es compl√®tes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le Na√Øf Saisonnier : pr√©diction = valeur de la m√™me semaine l'ann√©e pr√©c√©dente\n",
    "# On cr√©e un lag de 52 semaines\n",
    "df_temp = df.copy()\n",
    "df_temp['TauxGrippe_lag52'] = df_temp.groupby('region_name')['TauxGrippe'].shift(52)\n",
    "\n",
    "# Filtrer sur la p√©riode de validation\n",
    "df_val_seasonal = df_temp[df_temp['week'].isin(val_weeks)].dropna(subset=['TauxGrippe_lag52'])\n",
    "\n",
    "y_true_seasonal = df_val_seasonal['TauxGrippe'].values\n",
    "y_pred_naive_seasonal = df_val_seasonal['TauxGrippe_lag52'].values\n",
    "\n",
    "if len(y_pred_naive_seasonal) > 0:\n",
    "    res_naive_seasonal = evaluate_model(y_true_seasonal, y_pred_naive_seasonal, \"Na√Øf Saisonnier (lag 52)\")\n",
    "    results.append(res_naive_seasonal)\n",
    "    plot_predictions(y_true_seasonal, y_pred_naive_seasonal, \"Na√Øf Saisonnier\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas assez de donn√©es pour le mod√®le na√Øf saisonnier (n√©cessite 1 an d'historique)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Moyenne Mobile\n",
    "\n",
    "$$\\hat{y}_{T+h|T} = \\bar{y} = \\frac{1}{T}(y_1 + ... + y_T)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le Moyenne Mobile (sur 4 semaines)\n",
    "y_pred_ma4 = df_val_clean['TauxGrippe_rolling_mean_4'].values\n",
    "\n",
    "res_ma4 = evaluate_model(y_val.values, y_pred_ma4, \"Moyenne Mobile (4 semaines)\")\n",
    "results.append(res_ma4)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_ma4, \"Moyenne Mobile 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Moyenne Historique par R√©gion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne historique par r√©gion (calcul√©e sur le train)\n",
    "mean_by_region = df_train.groupby('region_name')['TauxGrippe'].mean()\n",
    "\n",
    "# Appliquer aux donn√©es de validation\n",
    "y_pred_mean_region = df_val_clean['region_name'].map(mean_by_region).values\n",
    "\n",
    "res_mean_region = evaluate_model(y_val.values, y_pred_mean_region, \"Moyenne Historique par R√©gion\")\n",
    "results.append(res_mean_region)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_mean_region, \"Moyenne par R√©gion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Mod√®le D√©rive (Drift)\n",
    "\n",
    "$$\\hat{y}_{T+h|T} = y_T + h \\left( \\frac{y_T - y_1}{T-1} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le D√©rive par r√©gion\n",
    "def compute_drift_prediction(group):\n",
    "    \"\"\"Calcule la pr√©diction par d√©rive pour un groupe (r√©gion).\"\"\"\n",
    "    y_T = group['TauxGrippe_lag1'].values\n",
    "    y_1 = group['TauxGrippe_lag4'].values  # Approximation avec lag4\n",
    "    T = 4  # Fen√™tre de 4 semaines\n",
    "    h = 1  # Horizon de 1 semaine\n",
    "    drift = h * (y_T - y_1) / (T - 1)\n",
    "    return y_T + drift\n",
    "\n",
    "# Application\n",
    "y_pred_drift = df_val_clean.groupby('region_name').apply(\n",
    "    lambda x: pd.Series(compute_drift_prediction(x), index=x.index)\n",
    ").values.flatten()\n",
    "\n",
    "# R√©ordonner selon l'index original\n",
    "df_val_clean['pred_drift'] = compute_drift_prediction(df_val_clean)\n",
    "y_pred_drift = df_val_clean['pred_drift'].values\n",
    "\n",
    "res_drift = evaluate_model(y_val.values, y_pred_drift, \"Mod√®le D√©rive (Drift)\")\n",
    "results.append(res_drift)\n",
    "\n",
    "# Nettoyer\n",
    "df_val_clean.drop('pred_drift', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: blue;\">PARTIE 2 : R√âGRESSION LIN√âAIRE</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">8. R√©gression Lin√©aire</span>\n",
    "\n",
    "### 8.1 R√©gression Lin√©aire Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©gression Lin√©aire simple\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "\n",
    "res_lr = evaluate_model(y_val.values, y_pred_lr, \"R√©gression Lin√©aire\")\n",
    "results.append(res_lr)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_lr, \"R√©gression Lin√©aire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients les plus importants\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': lr.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"üìä Top 10 coefficients (R√©gression Lin√©aire) :\")\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 R√©gression Ridge (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©gression Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_val)\n",
    "\n",
    "res_ridge = evaluate_model(y_val.values, y_pred_ridge, \"R√©gression Ridge\")\n",
    "results.append(res_ridge)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_ridge, \"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 R√©gression Lasso (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©gression Lasso\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_val)\n",
    "\n",
    "res_lasso = evaluate_model(y_val.values, y_pred_lasso, \"R√©gression Lasso\")\n",
    "results.append(res_lasso)\n",
    "\n",
    "# Features s√©lectionn√©es par Lasso\n",
    "lasso_coef = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': lasso.coef_\n",
    "})\n",
    "n_selected = (lasso_coef['coefficient'] != 0).sum()\n",
    "print(f\"\\nüìä Lasso a s√©lectionn√© {n_selected}/{len(X_train.columns)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: blue;\">PARTIE 3 : MOD√àLES ARIMA</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">9. Mod√®les ARIMA</span>\n",
    "\n",
    "ARIMA n√©cessite une s√©rie temporelle univari√©e. On va l'appliquer par r√©gion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de stationnarit√© (Augmented Dickey-Fuller)\n",
    "def test_stationarity(series, region_name):\n",
    "    \"\"\"Test ADF pour v√©rifier la stationnarit√©.\"\"\"\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"\\nüìä Test ADF - {region_name}\")\n",
    "    print(f\"   Statistique ADF : {result[0]:.4f}\")\n",
    "    print(f\"   p-value         : {result[1]:.4f}\")\n",
    "    print(f\"   Stationnaire    : {'Oui' if result[1] < 0.05 else 'Non'}\")\n",
    "    return result[1] < 0.05\n",
    "\n",
    "# Test sur une r√©gion exemple\n",
    "region_test = 'ILE-DE-FRANCE'\n",
    "series_test = df_train[df_train['region_name'] == region_test]['TauxGrippe']\n",
    "test_stationarity(series_test, region_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA par r√©gion (on prend quelques r√©gions pour l'exemple)\n",
    "regions_to_model = df['region_name'].unique()[:5]  # 5 premi√®res r√©gions\n",
    "\n",
    "arima_predictions = []\n",
    "arima_actuals = []\n",
    "\n",
    "for region in regions_to_model:\n",
    "    print(f\"\\nüîÑ Mod√®le ARIMA pour {region}...\")\n",
    "    \n",
    "    # Donn√©es de la r√©gion\n",
    "    train_region = df_train[df_train['region_name'] == region]['TauxGrippe'].values\n",
    "    val_region = df_val[df_val['region_name'] == region]['TauxGrippe'].values\n",
    "    \n",
    "    try:\n",
    "        # Fit ARIMA(1,1,1) - param√®tres simples\n",
    "        model = ARIMA(train_region, order=(1, 1, 1))\n",
    "        fitted = model.fit()\n",
    "        \n",
    "        # Pr√©dictions\n",
    "        predictions = fitted.forecast(steps=len(val_region))\n",
    "        \n",
    "        arima_predictions.extend(predictions)\n",
    "        arima_actuals.extend(val_region)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(val_region, predictions))\n",
    "        print(f\"   RMSE : {rmse:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Erreur : {e}\")\n",
    "\n",
    "# √âvaluation globale ARIMA\n",
    "if len(arima_predictions) > 0:\n",
    "    res_arima = evaluate_model(np.array(arima_actuals), np.array(arima_predictions), \"ARIMA(1,1,1)\")\n",
    "    results.append(res_arima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: blue;\">PARTIE 4 : MOD√àLES MACHINE LEARNING</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">10. Random Forest</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "\n",
    "res_rf = evaluate_model(y_val.values, y_pred_rf, \"Random Forest\")\n",
    "results.append(res_rf)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - Random Forest\n",
    "fi_rf = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(fi_rf['feature'][:15], fi_rf['importance'][:15], color='forestgreen')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Features - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fi_rf.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">11. XGBoost</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=False)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "res_xgb = evaluate_model(y_val.values, y_pred_xgb, \"XGBoost\")\n",
    "results.append(res_xgb)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - XGBoost\n",
    "fi_xgb = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(fi_xgb['feature'][:15], fi_xgb['importance'][:15], color='darkorange')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Features - XGBoost', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">12. LightGBM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train,\n",
    "              eval_set=[(X_val, y_val)])\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_val)\n",
    "\n",
    "res_lgb = evaluate_model(y_val.values, y_pred_lgb, \"LightGBM\")\n",
    "results.append(res_lgb)\n",
    "\n",
    "plot_predictions(y_val.values, y_pred_lgb, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color: blue;\">PARTIE 5 : BENCHMARK & COMPARAISON</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">13. Tableau R√©capitulatif des Performances</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du DataFrame de benchmark\n",
    "benchmark_df = pd.DataFrame(results)\n",
    "benchmark_df = benchmark_df.sort_values('RMSE')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"                    üìä BENCHMARK DES MOD√àLES\")\n",
    "print(\"=\"*80)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du benchmark\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# RMSE\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(benchmark_df)))\n",
    "axes[0].barh(benchmark_df['model'], benchmark_df['RMSE'], color=colors)\n",
    "axes[0].set_xlabel('RMSE (plus bas = meilleur)')\n",
    "axes[0].set_title('Comparaison RMSE', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# MAE\n",
    "axes[1].barh(benchmark_df['model'], benchmark_df['MAE'], color=colors)\n",
    "axes[1].set_xlabel('MAE (plus bas = meilleur)')\n",
    "axes[1].set_title('Comparaison MAE', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# R¬≤\n",
    "benchmark_sorted_r2 = benchmark_df.sort_values('R2', ascending=False)\n",
    "colors_r2 = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(benchmark_sorted_r2)))\n",
    "axes[2].barh(benchmark_sorted_r2['model'], benchmark_sorted_r2['R2'], color=colors_r2)\n",
    "axes[2].set_xlabel('R¬≤ (plus haut = meilleur)')\n",
    "axes[2].set_title('Comparaison R¬≤', fontsize=12, fontweight='bold')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('benchmark_modeles.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleur mod√®le\n",
    "best_model = benchmark_df.iloc[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ MEILLEUR MOD√àLE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Mod√®le : {best_model['model']}\")\n",
    "print(f\"   RMSE   : {best_model['RMSE']:.2f}\")\n",
    "print(f\"   MAE    : {best_model['MAE']:.2f}\")\n",
    "print(f\"   R¬≤     : {best_model['R2']:.4f}\")\n",
    "print(f\"   MAPE   : {best_model['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">14. G√©n√©ration des Submissions CSV</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour cr√©er un fichier submission\n",
    "def create_submission(model, model_name, X_data, df_data, filename):\n",
    "    \"\"\"\n",
    "    Cr√©e un fichier CSV de soumission au format attendu.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_data)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'Id': df_data['Id'].values,\n",
    "        'week': df_data['week'].values,\n",
    "        'region_name': df_data['region_name'].values,\n",
    "        'TauxGrippe_pred': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"‚úÖ Submission sauvegard√©e : {filename}\")\n",
    "    return submission\n",
    "\n",
    "# Cr√©er les submissions pour les meilleurs mod√®les\n",
    "print(\"\\nüìÑ G√âN√âRATION DES FICHIERS SUBMISSION\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission Random Forest\n",
    "sub_rf = create_submission(rf, \"Random Forest\", X_val, df_val_clean, \"submission_random_forest.csv\")\n",
    "sub_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission XGBoost\n",
    "sub_xgb = create_submission(xgb_model, \"XGBoost\", X_val, df_val_clean, \"submission_xgboost.csv\")\n",
    "sub_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission LightGBM\n",
    "sub_lgb = create_submission(lgb_model, \"LightGBM\", X_val, df_val_clean, \"submission_lightgbm.csv\")\n",
    "sub_lgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green;\">15. Sauvegarde du Benchmark</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du tableau de benchmark\n",
    "benchmark_df.to_csv('benchmark_modeles.csv', index=False)\n",
    "print(\"‚úÖ Benchmark sauvegard√© : benchmark_modeles.csv\")\n",
    "\n",
    "# Affichage final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                    ‚úÖ MOD√âLISATION TERMIN√âE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìÅ Fichiers g√©n√©r√©s :\")\n",
    "print(\"   ‚Ä¢ benchmark_modeles.csv\")\n",
    "print(\"   ‚Ä¢ benchmark_modeles.png\")\n",
    "print(\"   ‚Ä¢ submission_random_forest.csv\")\n",
    "print(\"   ‚Ä¢ submission_xgboost.csv\")\n",
    "print(\"   ‚Ä¢ submission_lightgbm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color: green;\">16. R√©sum√© & Conclusions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"                    üìä R√âSUM√â DE LA MOD√âLISATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìå DONN√âES\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   Observations totales  : {len(df):,}\")\n",
    "print(f\"   Train                 : {len(df_train_clean):,}\")\n",
    "print(f\"   Validation            : {len(df_val_clean):,}\")\n",
    "print(f\"   Features utilis√©es    : {len(features_with_dummies)}\")\n",
    "\n",
    "print(\"\\nüìå MOD√àLES TEST√âS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   ‚Ä¢ Mod√®les Na√Øfs : Persistance, Saisonnier, Moyenne Mobile, Drift\")\n",
    "print(\"   ‚Ä¢ R√©gression : Lin√©aire, Ridge, Lasso\")\n",
    "print(\"   ‚Ä¢ S√©ries Temporelles : ARIMA\")\n",
    "print(\"   ‚Ä¢ Machine Learning : Random Forest, XGBoost, LightGBM\")\n",
    "\n",
    "print(\"\\nüìå R√âSULTATS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   üèÜ Meilleur mod√®le : {best_model['model']}\")\n",
    "print(f\"      RMSE : {best_model['RMSE']:.2f}\")\n",
    "print(f\"      R¬≤   : {best_model['R2']:.4f}\")\n",
    "\n",
    "print(\"\\nüìå OBSERVATIONS CL√âS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   ‚úì Les lags (valeurs pass√©es) sont les features les plus importantes\")\n",
    "print(\"   ‚úì Les requ√™tes Google apportent de l'information pr√©dictive\")\n",
    "print(\"   ‚úì La saisonnalit√© est bien capt√©e par les mod√®les ML\")\n",
    "print(\"   ‚úì Les mod√®les ensemblistes (RF, XGB, LGB) surpassent les baselines\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
